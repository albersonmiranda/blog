---
title: Introdução ao {mlr3} framework
author: Alberson Miranda
date: '2020-12-21'
slug: [introducao-ao-mlr3]
categories:
  - Machine Learning
tags:
  - mlr3
  - R
description: Uma introdução ao framework de machine learning mlr3, um pacote de R.
featured: yes
draft: true
featureImage: img/mlr3verse.svg
thumbnail: images/mlr3.png
shareImage: images/posts/2020-12-20 - intro-mlr3.jpeg
codeMaxLines: 10
codeLineNumbers: no
figurePositionShow: yes
---

<script src="index_files/header-attrs/header-attrs.js"></script>


<p>Esse é o primeiro post de uma série que irá tratar sobre o ecossistema {mlr3}. Ele é mais completo mas também muito mais complexo do que seu predecessor, o {mlr}, que teve sua versão inicial publicada no CRAN em 2013. O ecossistema permite um framework agnóstico (i.e. não depende dos algoritmos escolhidos), extensível e orientado a objeto, e, atualmente, permite vários tipos de tarefas, como classificação, regressão, análise de sobrevivência, forecasting, clustering, dentre outros. O {mlr3} tem diversas vantagens e elas ficarão claras ao longo dessas postagens.</p>
<div id="introdução" class="section level1">
<h1>INTRODUÇÃO</h1>
<p>O workflow padrão de machine learning consiste em</p>
<ol style="list-style-type: decimal">
<li>dividir sua amostra em treino e teste (<em>split</em>)</li>
<li>escolher o algoritmo<a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a> apropriado para o tipo de tarefa</li>
<li>passar a amostra de treino ao algoritmo para criar um modelo do relacionamento entre a variável de resposta (<em>output features</em>)e as explicativas (<em>input features</em>)</li>
<li>passar os dados de testes no modelo treinado para produzir predições</li>
<li>comparar as predições com os dados da amostra</li>
<li>mensurar a performance do modelo através de medidas de acurácia estabelecidas</li>
</ol>
<p><img src="img/basics.svg" /></p>
<p>O processo de repetir esse workflow várias vezes, separando a amostra treino em várias partes diferentes e usando outras como <em>fake test samples</em> é chamado de <em>resampling</em> e é um processo vital para a etapa de calibragem do modelo e para evitar o <em>overfitting</em> (será abordado em futuros posts).</p>
<p>Dependendo dos dados, do tipo de tarefa e algoritmo escolhido, podem ser necessários vários filtros, como normalização, <em>feature selection</em> e tratamento de <em>outliers</em> e dados faltantes. Para esses casos, o {mlr3} tem novas soluções que se destacam com muita vantagem em relação não só ao seu predecessor {mlr} como também a outros <em>frameworks</em> de <em>machine learning</em> em R, como o {caret} e o {tidymodels}. Abordaremos esses <em>pipelines</em> nos próximos posts.</p>
</div>
<div id="direto-ao-ponto" class="section level1">
<h1>DIRETO AO PONTO</h1>
<p>Nesse post serão trabalhadas as funcionalidades básicas do pacote. Para isso, usaremos um dos <em>datasets</em> inclusos no R, o <code>swiss</code>. Esse <em>dataset</em> consiste na medição padronizada da fertilidade e indicadores socioeconômicos de 47 províncias da Suíça em 1888.</p>
<pre class="r"><code># criando dataframe
data = swiss

# overview
skimr::skim(data)</code></pre>
<table>
<caption><span id="tab:data">Table 1: </span>Data summary</caption>
<tbody>
<tr class="odd">
<td align="left">Name</td>
<td align="left">data</td>
</tr>
<tr class="even">
<td align="left">Number of rows</td>
<td align="left">47</td>
</tr>
<tr class="odd">
<td align="left">Number of columns</td>
<td align="left">6</td>
</tr>
<tr class="even">
<td align="left">_______________________</td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="left">Column type frequency:</td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="left">numeric</td>
<td align="left">6</td>
</tr>
<tr class="odd">
<td align="left">________________________</td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="left">Group variables</td>
<td align="left">None</td>
</tr>
</tbody>
</table>
<p><strong>Variable type: numeric</strong></p>
<table>
<thead>
<tr class="header">
<th align="left">skim_variable</th>
<th align="right">n_missing</th>
<th align="right">complete_rate</th>
<th align="right">mean</th>
<th align="right">sd</th>
<th align="right">p0</th>
<th align="right">p25</th>
<th align="right">p50</th>
<th align="right">p75</th>
<th align="right">p100</th>
<th align="left">hist</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Fertility</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">70.14</td>
<td align="right">12.49</td>
<td align="right">35.00</td>
<td align="right">64.70</td>
<td align="right">70.40</td>
<td align="right">78.45</td>
<td align="right">92.5</td>
<td align="left">▂▂▇▇▅</td>
</tr>
<tr class="even">
<td align="left">Agriculture</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">50.66</td>
<td align="right">22.71</td>
<td align="right">1.20</td>
<td align="right">35.90</td>
<td align="right">54.10</td>
<td align="right">67.65</td>
<td align="right">89.7</td>
<td align="left">▃▃▆▇▅</td>
</tr>
<tr class="odd">
<td align="left">Examination</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">16.49</td>
<td align="right">7.98</td>
<td align="right">3.00</td>
<td align="right">12.00</td>
<td align="right">16.00</td>
<td align="right">22.00</td>
<td align="right">37.0</td>
<td align="left">▅▇▆▂▂</td>
</tr>
<tr class="even">
<td align="left">Education</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">10.98</td>
<td align="right">9.62</td>
<td align="right">1.00</td>
<td align="right">6.00</td>
<td align="right">8.00</td>
<td align="right">12.00</td>
<td align="right">53.0</td>
<td align="left">▇▃▁▁▁</td>
</tr>
<tr class="odd">
<td align="left">Catholic</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">41.14</td>
<td align="right">41.70</td>
<td align="right">2.15</td>
<td align="right">5.20</td>
<td align="right">15.14</td>
<td align="right">93.12</td>
<td align="right">100.0</td>
<td align="left">▇▁▁▁▅</td>
</tr>
<tr class="even">
<td align="left">Infant.Mortality</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">19.94</td>
<td align="right">2.91</td>
<td align="right">10.80</td>
<td align="right">18.15</td>
<td align="right">20.00</td>
<td align="right">21.70</td>
<td align="right">26.6</td>
<td align="left">▁▂▇▆▂</td>
</tr>
</tbody>
</table>
<p>Dentre as varáveis disponíveis, podemos escolher modelar a mortalidade infantil <code>Infant.Mortality</code> baseada nas demais features, que são:</p>
<ul>
<li><code>Fertility</code>: Medida de fertilidade. Assim como a mortalidade infantil, está escalonada entre 0-100.</li>
<li><code>Agriculture</code>: Percentual de homens envolvidos em agricultura como ocupação.</li>
<li><code>Examination</code>: Percentual de alistados bem avaliados nos exames do exército.</li>
<li><code>Education</code>: Percentual dos alistados com educação superior ao primário.</li>
<li><code>Catholic</code>: Percentual de católicos (em oposto a protestantes).</li>
</ul>
<p>Começamos pela criação da <em>task</em>. Como queremos realizar predições para uma variável numérica contínua, é uma tarefa de regressão. O {mlr3} trabalha com a classe R6, o que torna seu manuseio mais parecido com outras linguagens orientadas a objeto, como o Python.</p>
<pre class="r"><code># importando pacote
library(mlr3verse)

# criando task
task_swiss = TaskRegr$new(
  id = &quot;swiss&quot;,
  backend = data,
  target = &quot;Infant.Mortality&quot;
)

# verificando
task_swiss</code></pre>
<pre><code>## &lt;TaskRegr:swiss&gt; (47 x 6)
## * Target: Infant.Mortality
## * Properties: -
## * Features (5):
##   - dbl (3): Agriculture, Catholic, Fertility
##   - int (2): Education, Examination</code></pre>
<pre class="r"><code># visualizando
autoplot(task_swiss, type = &quot;pairs&quot;)</code></pre>
<p><img src="index_files/figure-html/task-1.png" width="672" /></p>
<p>Podemos verificar que apenas a fertilidade é linearmente correlacionada com a mortalidade infantil — quanto maior a fertilidade, maior a mortalidade —, e podemos esperar que tenha maior peso nas predições. As demais variáveis não apresentam correlação linear significativa com a variável de resposta. Entretanto, apresentam correlação moderada ou forte entre si, mas não a ponto de apresentar colinearidade, o que demandaria tratamento.</p>
<p>Agora selecionamos o algoritmo<a href="#fn2" class="footnote-ref" id="fnref2"><sup>2</sup></a> que será usado para treinar o modelo. Escolhi aqui o <em>XGBoost</em>. A lista completa pode ser acessada <a href="https://mlr3extralearners.mlr-org.com/articles/learners/learner_status.html">por essa lista estática</a>, <a href="https://mlr3extralearners.mlr-org.com/articles/learners/list_learners.html">por essa lista dinâmica</a> ou pela função <code>mlr3extralearners::list_mlr3learners()</code>. É importante deixar claro que os algoritmos não são implementados pelo ecossistema do {mlr3}, mas apenas o <em>workflow</em>. Isso significa que o algoritmo <em>XGBoost</em>, por exemplo, não está incluído nos pacotes do ecossistema, sendo necessário sua instalação<a href="#fn3" class="footnote-ref" id="fnref3"><sup>3</sup></a>.</p>
<pre class="r"><code># definindo o learner
l_xgboost = lrn(&quot;regr.xgboost&quot;)

# checando
l_xgboost</code></pre>
<pre><code>## &lt;LearnerRegrXgboost:regr.xgboost&gt;
## * Model: -
## * Parameters: nrounds=1, verbose=0
## * Packages: xgboost
## * Predict Type: response
## * Feature types: logical, integer, numeric
## * Properties: importance, missings, weights</code></pre>
<p>Vamos etender o que o objeto <code>l_xgboost</code> nos diz.</p>
<ol style="list-style-type: decimal">
<li><strong>Model</strong>: Vazio, pois ainda não há um modelo treinado</li>
<li><strong>Parameters</strong>: Os hiperparâmetros a serem escolhidos e tunados para performance do modelo</li>
<li><strong>Packages</strong>: O pacote onde o algorítmo foi implementado e de onde será importado pelo {mlr3}</li>
<li><strong>Predict Type</strong>: Se “response” a predição é retornada ou como 0 ou 1, no caso de classificação, ou num valor para variável de resposta, no caso de regressão — neste caso, será a mortalidade infantil escalonada no intervalo [1, 100]. Se “prob”, para classificação, a predição retorna a probabilidade entre 0 e 1.</li>
<li><strong>Feature Type</strong>: Os tipos de variáveis que o algoritmo é capaz de manipular. No caso do <em>XGBoost</em>, por exemplo, apenas variáveis numéricas podem ser utilizadas. Isso quer dizer que os fatores devem ser convertidos em valores binários (i.e. 0 ou 1), ou seja, deve-se tornar a matriz esparsa.</li>
<li><strong>Properties</strong>: Propriedades e capacidades adicionais do algoritmo. Neste caso, o <strong>XGBoost</strong> possui a capacidade de computar e retornar os valores da importâncias das <em>features</em> para o modelo; a capacidade de trabalhar com dados faltantes (<em>missings</em>); a capacidade de computar e retornar os pesos associados às <em>features</em>.</li>
</ol>
<p>Como pode ver em <em>parameters</em>, não há nenhum hiperparâmetro configurado. Podemos acessá-los da seguinte maneira:</p>
<pre class="r"><code># acessando hiperparâmetros
head(as.data.table(l_xgboost$param_set))</code></pre>
<pre><code>##                  id    class lower upper               levels nlevels
## 1:          booster ParamFct    NA    NA gbtree,gblinear,dart       3
## 2:        watchlist ParamUty    NA    NA                          Inf
## 3:              eta ParamDbl     0     1                          Inf
## 4:            gamma ParamDbl     0   Inf                          Inf
## 5:        max_depth ParamInt     0   Inf                          Inf
## 6: min_child_weight ParamDbl     0   Inf                          Inf
##    is_bounded special_vals default storage_type  tags
## 1:       TRUE    &lt;list[0]&gt;  gbtree    character train
## 2:      FALSE    &lt;list[0]&gt;                 list train
## 3:       TRUE    &lt;list[0]&gt;     0.3      numeric train
## 4:      FALSE    &lt;list[0]&gt;       0      numeric train
## 5:      FALSE    &lt;list[0]&gt;       6      integer train
## 6:      FALSE    &lt;list[0]&gt;       1      numeric train</code></pre>
<p>Como o <em>tunning</em> de hiperparâmetros não é o assunto, vamos apenas configurar algumas coisas básicas:</p>
<pre class="r"><code># hiperparâmetros
l_xgboost$param_set$values = list(
  # mandando o algoritmo parar depois de 10 iterações sem melhora no score
  early_stopping_rounds = 10,
  # mandando o algoritmo treinar mais lentamente
  eta = 0.1,
  # limitando profundidade da árvore
  max_depth = 5,
  # quantidade máxima de iterações
  nrounds = 100
)

# verificando
l_xgboost</code></pre>
<pre><code>## &lt;LearnerRegrXgboost:regr.xgboost&gt;
## * Model: -
## * Parameters: early_stopping_rounds=10, eta=0.1, max_depth=5,
##   nrounds=100
## * Packages: xgboost
## * Predict Type: response
## * Feature types: logical, integer, numeric
## * Properties: importance, missings, weights</code></pre>
</div>
<div id="treino-e-predição" class="section level1">
<h1>TREINO E PREDIÇÃO</h1>
<p>As próximas etapas são o treino e a predição — trataremos de <em>tunning</em> e <em>resampling</em> nos próximos posts. Primeiramente, o <em>split</em> do dataset em treino e teste. Para isso, usaremos a função <code>sample()</code> associada a dois métodos do objeto <code>task_swiss</code>, o <code>row_ids</code> e <code>nrow</code>. O primeiro enumera os índices de cada linha:</p>
<pre class="r"><code># método row_ids
task_swiss$row_ids</code></pre>
<pre><code>##  [1]  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25
## [26] 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47</code></pre>
<p>Enquanto o segundo retorna a quantidade de linhas do dataset:</p>
<pre class="r"><code># método row_ids
task_swiss$nrow</code></pre>
<pre><code>## [1] 47</code></pre>
<p>Assim, podemos selecionar os índice do dataset em duas amostras aleatórias:</p>
<pre class="r"><code># garantindo reprodutibilidade
set.seed(1)

# índices para amostra treino
train_set = sample(task_swiss$row_ids, 0.8 * task_swiss$nrow)

# índices para amostra teste
test_set = setdiff(task_swiss$row_ids, train_set)

# verificando
head(train_set)</code></pre>
<pre><code>## [1]  4 39  1 34 23 14</code></pre>
<p>Com os índices selecionados, podemos realizar nosso treino apenas nos 80% escolhidos aleatoriamente da amostra. :</p>
<pre class="r"><code># treino
l_xgboost$train(task_swiss, row_ids = train_set)</code></pre>
<pre><code>## [10:54:58] WARNING: amalgamation/../src/objective/regression_obj.cu:174: reg:linear is now deprecated in favor of reg:squarederror.
## [1]  train-rmse:17.576906 
## Will train until train_rmse hasn&#39;t improved in 10 rounds.
## 
## [2]  train-rmse:15.906290 
## [3]  train-rmse:14.400700 
## [4]  train-rmse:13.044603 
## [5]  train-rmse:11.824566 
## [6]  train-rmse:10.726380 
## [7]  train-rmse:9.739924 
## [8]  train-rmse:8.854416 
## [9]  train-rmse:8.054627 
## [10] train-rmse:7.335248 
## [11] train-rmse:6.688681 
## [12] train-rmse:6.109197 
## [13] train-rmse:5.587444 
## [14] train-rmse:5.119703 
## [15] train-rmse:4.699141 
## [16] train-rmse:4.312882 
## [17] train-rmse:3.971956 
## [18] train-rmse:3.657235 
## [19] train-rmse:3.366412 
## [20] train-rmse:3.103006 
## [21] train-rmse:2.865532 
## [22] train-rmse:2.647503 
## [23] train-rmse:2.448978 
## [24] train-rmse:2.268340 
## [25] train-rmse:2.106096 
## [26] train-rmse:1.954928 
## [27] train-rmse:1.814957 
## [28] train-rmse:1.688345 
## [29] train-rmse:1.572037 
## [30] train-rmse:1.467292 
## [31] train-rmse:1.374028 
## [32] train-rmse:1.281157 
## [33] train-rmse:1.196213 
## [34] train-rmse:1.116619 
## [35] train-rmse:1.040653 
## [36] train-rmse:0.975037 
## [37] train-rmse:0.909925 
## [38] train-rmse:0.852961 
## [39] train-rmse:0.803740 
## [40] train-rmse:0.757104 
## [41] train-rmse:0.713849 
## [42] train-rmse:0.672327 
## [43] train-rmse:0.634015 
## [44] train-rmse:0.595590 
## [45] train-rmse:0.560054 
## [46] train-rmse:0.527118 
## [47] train-rmse:0.498028 
## [48] train-rmse:0.469220 
## [49] train-rmse:0.441418 
## [50] train-rmse:0.417214 
## [51] train-rmse:0.394707 
## [52] train-rmse:0.373728 
## [53] train-rmse:0.353631 
## [54] train-rmse:0.334691 
## [55] train-rmse:0.317351 
## [56] train-rmse:0.301512 
## [57] train-rmse:0.286208 
## [58] train-rmse:0.270775 
## [59] train-rmse:0.256299 
## [60] train-rmse:0.243574 
## [61] train-rmse:0.230665 
## [62] train-rmse:0.218585 
## [63] train-rmse:0.208203 
## [64] train-rmse:0.197173 
## [65] train-rmse:0.186830 
## [66] train-rmse:0.177357 
## [67] train-rmse:0.168414 
## [68] train-rmse:0.160592 
## [69] train-rmse:0.152636 
## [70] train-rmse:0.144257 
## [71] train-rmse:0.137330 
## [72] train-rmse:0.130671 
## [73] train-rmse:0.123992 
## [74] train-rmse:0.117501 
## [75] train-rmse:0.111853 
## [76] train-rmse:0.106568 
## [77] train-rmse:0.101401 
## [78] train-rmse:0.096543 
## [79] train-rmse:0.091538 
## [80] train-rmse:0.087073 
## [81] train-rmse:0.082596 
## [82] train-rmse:0.078167 
## [83] train-rmse:0.074190 
## [84] train-rmse:0.070875 
## [85] train-rmse:0.067654 
## [86] train-rmse:0.064362 
## [87] train-rmse:0.061019 
## [88] train-rmse:0.058160 
## [89] train-rmse:0.055346 
## [90] train-rmse:0.052694 
## [91] train-rmse:0.050063 
## [92] train-rmse:0.047896 
## [93] train-rmse:0.045524 
## [94] train-rmse:0.043504 
## [95] train-rmse:0.041372 
## [96] train-rmse:0.039341 
## [97] train-rmse:0.037627 
## [98] train-rmse:0.035837 
## [99] train-rmse:0.034289 
## [100]    train-rmse:0.032903</code></pre>
<pre class="r"><code># verificando
l_xgboost$model</code></pre>
<pre><code>## ##### xgb.Booster
## raw: 106.3 Kb 
## call:
##   xgboost::xgb.train(data = data, nrounds = 100L, watchlist = list(
##     train = &lt;pointer: 0x000000001b936bd0&gt;), early_stopping_rounds = 10L, 
##     eta = 0.1, max_depth = 5L, objective = &quot;reg:linear&quot;)
## params (as set within xgb.train):
##   eta = &quot;0.1&quot;, max_depth = &quot;5&quot;, objective = &quot;reg:linear&quot;, validate_parameters = &quot;TRUE&quot;
## xgb.attributes:
##   best_iteration, best_msg, best_ntreelimit, best_score, niter
## callbacks:
##   cb.print.evaluation(period = print_every_n)
##   cb.evaluation.log()
##   cb.early.stop(stopping_rounds = early_stopping_rounds, maximize = maximize, 
##     verbose = verbose)
## # of features: 5 
## niter: 100
## best_iteration : 100 
## best_ntreelimit : 100 
## best_score : 0.032903 
## best_msg : [100] train-rmse:0.032903 
## nfeatures : 5 
## evaluation_log:
##     iter train_rmse
##        1  17.576906
##        2  15.906290
## ---                
##       99   0.034289
##      100   0.032903</code></pre>
<p>Como podemos ver, na primeira iteração o modelo obteve <em>rmse</em><a href="#fn4" class="footnote-ref" id="fnref4"><sup>4</sup></a>. de 17.5, o que é alto considerando a escala [1-100] da mortalidade infantil. O modelo foi aumentando sua precisão no treino até 0.03, o que não significa que sua performance permaneça nesse nível quando extrapolado para a amostra teste ou novos dados, mas é um bom sinal. O esperado é que a performance real do modelo, após ser aplicado à amostra teste, fique entre a iteração inicial e final. Se ficar <em>melhor</em> do que a performance do teste, alguma coisa certamente está errada.</p>
<p>Vamos verificar qual a performance real após realizarmos as predições na amostra teste:</p>
<pre class="r"><code># predições
preds = l_xgboost$predict(task_swiss, row_ids = test_set)

# verificando
preds</code></pre>
<pre><code>## &lt;PredictionRegr&gt; for 10 observations:
##     row_id truth response
##          8  24.9 20.18500
##         11  24.5 20.37197
##         13  19.1 15.56200
## ---                      
##         31  15.1 16.39225
##         36  17.8 19.43584
##         40  20.5 19.21186</code></pre>
<pre class="r"><code># acurácia
preds$score(list(
  msr(&quot;regr.rmse&quot;),
  msr(&quot;regr.mae&quot;)
))</code></pre>
<pre><code>## regr.rmse  regr.mae 
##  2.787566  2.414017</code></pre>
<pre class="r"><code># visualizando
autoplot(preds)</code></pre>
<pre><code>## `geom_smooth()` using formula &#39;y ~ x&#39;</code></pre>
<p><img src="index_files/figure-html/predictions-1.png" width="672" /></p>
<p>A <em>rmse</em> do modelo na amostra teste ficou em apenas 2.79 unidades, o que é uma performance muito boa!</p>
</div>
<div class="footnotes">
<hr />
<ol>
<li id="fn1"><p>No {mlr3} é chamado de <em>learner</em>.<a href="#fnref1" class="footnote-back">↩︎</a></p></li>
<li id="fn2"><p>Aqui trabalharemos apenas com um, mas em posts futuros utilizaremos de diversas formas — pipelines com diferentes <em>features</em>, <em>stacking</em> etc.<a href="#fnref2" class="footnote-back">↩︎</a></p></li>
<li id="fn3"><p>Tanto no objeto criado quanto nas listas citadas constam os pacotes onde os algoritmos foram implementados.<a href="#fnref3" class="footnote-back">↩︎</a></p></li>
<li id="fn4"><p>Raiz do Erro Médio Quadrático<a href="#fnref4" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
